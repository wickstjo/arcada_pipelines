package com.example.myproject

// SHARED
import org.apache.flink.streaming.api.scala._
import scala.collection.JavaConverters._

// import utils.{kafka_utils, cassandra_utils, topo_utils}
import schemas.surface_data.{sensor_1A => SENSOR_SCHEMA, defective_tile => DEFECT_SCHEMA}
import utils.{kafka_utils, cassandra_utils, topo_utils}

object Main extends App {

    // CREATE STREAM PROCESSING ENVIRONMENT
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    // env.setRestartStrategy(
    //     RestartStrategies.fixedDelayRestart(
    //         maxAttempts = 0, // Disable restarts
    //         delayBetweenAttempts = 0 // No delay between restart attempts
    //     )
    // )

    // USE REGULAR KEY-VALUE CHECKPOINTING -- IN MILLISECONDS
    // env.enableCheckpointing(1000)

    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // TENSOR DIMENSIONS
    val vector_length: Int = 800
    val matrix_height: Int = 224
    val tensor_depth: Int = 3

    // OVERLAP CONFIG
    val large_tile_overlap: Int = 40
    val adjusted_matrix_height: Int = matrix_height - large_tile_overlap

    // TILE CONFIGS
    val n_mini_tiles: Int = 18

    // ANOMALY TOLERANCES
    val min_cable_radius: Double = 15.0
    val mini_delta_tolerance: Double = 0.22
    val cnn_defect_tolerance: Int = 3

    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // CREATE THE KAFKA INPUT SOURCE
    val kafka_input_topic: String = "surface_data.sensor_1A"
    val source_details = kafka_utils.input_source[SENSOR_SCHEMA](kafka_input_topic)
    val kafka_input_stream: DataStream[SENSOR_SCHEMA] = env
        .fromSource(source_details._1, source_details._2, source_details._3)
        .name("KAFKA INPUT SOURCE")
        .setParallelism(4)

    // kafka_input_stream
    //     .map(item => item)
    //     .name("FOO")
    //     .setParallelism(2)

    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    val vector_query: String = "INSERT INTO surface_data.sensor_1A (timestamp, serial_number, vector) values (?, ?, ?);"

    // GATHER VECTORS INTO SLIDING MATRIX WINDOW
    val sliding_matrix_stream: DataStream[topo_utils.SCALA_MATRIX] = kafka_input_stream
        .flatMap(new topo_utils.sliding_matrix_factory(
            matrix_height,
            adjusted_matrix_height,
            vector_query
        ))
        .name("VECTOR INGEST + SLIDING MATRIX")
        .setParallelism(4)

    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // ANALYZE LARGE TENSOR FOR ANOMALIES
    val defective_tile_stream: DataStream[topo_utils.DEFECT_OUTPUT] = sliding_matrix_stream
        .flatMap(new topo_utils.tensor_processing(
            vector_length,
            matrix_height,
            tensor_depth,
            adjusted_matrix_height,
            n_mini_tiles,
            min_cable_radius,
            mini_delta_tolerance,
            cnn_defect_tolerance
        ))
        .name("MATRIX PROCESSING")
        .setParallelism(64)

    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // val defect_query: String = """
    //     INSERT INTO surface_data.defects (
    //         timestamp, 
    //         tensor_hash, 
    //         cable_sector, 
    //         tile_max, 
    //         tile_min, 
    //         tile_delta, 
    //         tile_mean, 
    //         n_defects
    //     ) values (?, ?, ?, ?, ?, ?, ?, ?);
    // """

    // val defect_sink: DataStream[Boolean] = defective_tile_stream
    //     .flatMap(new topo_utils.defect_ingestion_factory(defect_query))
    //     .name("DEFECT INGESTION SINK")
    //     .setParallelism(1)


    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // // EXTRACT TOPO VECTOR FROM LARGER SCHEMA OBJECT
    // val vector_extraction_stream: DataStream[topo_utils.TOPO_VECTOR] = kafka_input_stream
    //     .map(item => {
    //         item.getDatapoints().asScala.map(_.toDouble).toArray
    //     })
    //     .name("Topo vector extraction")
    //     .setParallelism(2)

    // // GATHER VECTORS INTO SLIDING MATRIX WINDOW
    // val sliding_matrix_stream: DataStream[topo_utils.TOPO_MATRIX] = vector_extraction_stream
    //     .flatMap(new topo_utils.sliding_matrix_factory[topo_utils.TOPO_VECTOR](
    //         matrix_height,
    //         adjusted_matrix_height,
    //     ))
    //     .name("Sliding matrix accumulator")
    //     .setParallelism(2)

    // // // // CREATE A TENSOR FROM FULL MATRIX
    // // // val tensor_stream: DataStream[topo_utils.TOPO_TENSOR] = sliding_matrix_stream
    // // //     .flatMap(new topo_utils.tensor_factory(
    // // //         vector_length,
    // // //         matrix_height,
    // // //         tensor_depth,
    // // //     ))
    // // //     .name("Tensor creation")
    // // //     .setParallelism(3)

    // // // // CREATE MANY LARGE, OVERLAPPING TILES FROM TENSOR
    // // // val tile_stream: DataStream[topo_utils.TOPO_TENSOR] = tensor_stream
    // // //     .flatMap(new topo_utils.tensor_tile_factory(
    // // //         vector_length,
    // // //         matrix_height,
    // // //         adjusted_matrix_height,
    // // //     ))
    // // //     .name("Large tile creation")
    // // //     .setParallelism(3)

    // // // // ANALYZE LARGE TENSOR FOR ANOMALIES
    // // // val defective_tile_stream: DataStream[topo_utils.DEFECT_OUTPUT] = tile_stream
    // // //     .flatMap(new topo_utils.defect_detection_factory(
    // // //         matrix_height,
    // // //         n_mini_tiles,
    // // //         min_cable_radius,
    // // //         mini_delta_tolerance,
    // // //         cnn_defect_tolerance,
    // // //     ))
    // // //     .name("Large tile anomaly detection")
    // // //     .setParallelism(8)

    // // ANALYZE LARGE TENSOR FOR ANOMALIES
    // val defective_tile_stream: DataStream[topo_utils.DEFECT_OUTPUT] = sliding_matrix_stream
    //     .flatMap(new topo_utils.tensor_processing(
    //         vector_length,
    //         matrix_height,
    //         tensor_depth,
    //         adjusted_matrix_height,
    //         n_mini_tiles,
    //         min_cable_radius,
    //         mini_delta_tolerance,
    //         cnn_defect_tolerance
    //     ))
    //     .name("Tensor tile processing")
    //     .setParallelism(32)

    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // // PARSE LARGE TILE INTO KAFKA DEFECT SCHEMA
    // val kafka_defect_formatting: DataStream[DEFECT_SCHEMA] = defective_tile_stream
    //     .map(item => {

    //         // TRANSFORM SCALA LIST TO JAVA LIST ON EACH TENSOR DIMENSION
    //         val java_tensor: topo_utils.JAVA_TENSOR = item._1.map {
    //             inner => inner.map(_.toList.map(_.asInstanceOf[java.lang.Double]).asJava).toList.asJava
    //         }.toList.asJava

    //         // CAST TILE PROPERTIES TO DEFECT SCHEMA
    //         new DEFECT_SCHEMA(item._4, item._3, java_tensor)
    //     })
    //     .name("Kafka defect formatting")
    //     .setParallelism(1)

    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // // CASSANDRA QUERY STRING
    // val defect_query: String = """
    //     INSERT INTO surface_data.defects (
    //         timestamp, 
    //         tensor_hash, 
    //         cable_sector, 
    //         tile_max, 
    //         tile_min, 
    //         tile_delta, 
    //         tile_mean, 
    //         n_defects
    //     ) values (?, ?, ?, ?, ?, ?, ?, ?);
    // """

    // // INGEST DEFECTS VECTORS INTO CASSANDRA
    // val defect_formatting: DataStream[topo_utils.DEFECT_INGEST_FORM] = defective_tile_stream
    //     .map(item => {

    //         // EXTRACT TILE STATS FOR CLARITY
    //         var (large_mx, large_mn, large_delta, large_mean) = item._2

    //         // WHAT CABLE SECTOR PIPELINE HANDLES
    //         val topo_sector: String = "1A"

    //         // RETURN FULL OBJECT
    //         Tuple8(
    //             item._4,
    //             item._3,
    //             topo_sector,
    //             large_mx, 
    //             large_mn, 
    //             large_delta,
    //             large_mean,
    //             item._5,
    //         )
    //     })
    //     .name("Cassandra defect formatting")
    //     .setParallelism(1)

    // val defect_sink: DataStream[Boolean] = defect_formatting
    //     .flatMap(new cassandra_utils.defect_sink(defect_query))
    //     .name("Cassandra defect sink")
    //     .setParallelism(1)

    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    // FINALLY, START THE PIPELINE
    env.execute("TOPO SURFACE PROCESSING: SECTOR 1A")
}